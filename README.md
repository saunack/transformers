# Coding Transformers

This is a recreation of the code for transformers as described in the seminal paper by Google in 2018. References to each section in the paper for each component are mentioned in the code wherever needed. 

To test that the code works properly, please run `test.py` in an environment with `pytorch` installed.

## What's missing (todo)
- Tokenization
- Training data preparation
- Training loop

## References

[Original Paper](https://arxiv.org/pdf/1706.03762.pdf)

[YouTube guide for coding transformers](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py)

[A more detailed YouTube guide for coding transformers](https://www.youtube.com/watch?v=EPa98fyxZ-s)
